---
layout: post
title: 'Tree'
categories: [ML]
tags: Tree
---
  
  단일 트리 과적합 => 깊이 제한 (과소적합 모델 학습) - 앙상블 생성 예측 투표 => 이후 일반화 잘됨

  노드를 분할할때 Gini 를 활용할 수 있다.
  impurity : 불순도  (Leaf node 만이 불순도 0 을 가짐)

  gini - [1,2,3,...j] 리스트 중  그 노드에서의 데이터포인트를 랜덤으로 선택 했을때 맞게 고를 확률 P라면
  		Gini imp = 1- ∑ P²
from sklearn.tree import DecisionTreeClassifier    (criterion= 'entropy', max_depth=3 ...)

트리기반 모델의 장*단점

 - 이해와 설명이 쉽다.
 - 데이터 스케일의 영향을 거의 받지 않는다.


 - pre-pruning 을 사용하여도 과적합되는 경향이 있다.
 - 일반화 성능이 좋지 않다.


==> 이러한 과적합을 완화하기 위한 방법으로 랜덤 포레스트를 사용한다.


Random Forest 
: 여러 결정 트리들의 묶음

각 트리에서 예측한 데이터의 일부중 과적합을 보이는 것들을 평균을 내어 과적합의 양을 줄일 수 있다.
( 모델의 성능을 유지하면서 과적합을 줄일 수 있음)


**구축**

1) 부트스트램 생성

생성할 트리의 개수 : n_samples

n_samples 중에서 n_samples 수 만큼 무작위로 반복추출  ................ (한 샘플이 여러번 중복 추출될 수 있음)

알고리즘이 각 노드에서 후보 특성을 무작위로 선택 후 후보들 중에서 최선의 테스트를 찾는다.

또 후보특성을 고를때 매 노드마다 반복되므로 트리의 각 노드는 다른 후보 특성들을 사용하여 테스트를 만든다.

각 트리마다 가지는 데이터셋이 조금씩 다르며 , 각 트리에서 사용하는 특성도 다르게 만든다.

이때 특성을 몇 가지를 고를지는 max_features 를 사용한다.

max_feautres 값이 크다면 각 트리들은 비슷해지고 그 중 가장 최적화된 특성을 이용해 데이터에 적합이 될 것이다.
반대로 max_features의 값이 작다면 각 트리들은 달라지고 데이터에 맞추기 위해 깊이가 깊어지게 된다.



**예측 방법**

모든 트리의 예측을 진행한다.  
 - 회귀 ---- 예측들을 평균하여 최종 예측
 - 분류 ---- 레이블의 확률로 가장 가능성이 높은것을 예측

분류 예측

![다섯 개의 랜덤 결정 트리의 결정 경계와 예측한 확률을 평균내어 만든 결정 경계](https://github.com/VFV-main/VFV-main.github.io/blob/master/images/RF.png?raw=true)
(다섯 개의 랜덤 결정 트리의 결정 경계와 예측한 확률을 평균내어 만든 결정 경계)


* 부트스트랩 샘플링 때문에 한쪽 트리에 나타나는 훈련 포인트가 다른 트리에 포함되지 않을 수 있어 각 트리는 불완전하다.



단일 트리의 변수 중요도
![](https://github.com/VFV-main/VFV-main.github.io/blob/master/images/download.png?raw=true)


랜덤 포레스트 변수 중요도
![](https://github.com/VFV-main/ML/blob/main/download.png?raw=true)


	위의 결과 처럼 단일 트리보다 더 다양한 시각으로 데이터를 분석할 수 있다.

	하지만 랜덤포레스트는 단일 트리보다 설명하기 깊이가 깊어지는 경향이 있어 설명하기 어려워 진다는 단점이 있다.
    다른 선형 모델보다 메모리 사용이 많고 훈련,예측이 느림 (속도와 메모리가 중요하다면 선형모델 추천)
    또한, 고차원의 희소한 데이터에서는 잘 작동하지않음 (선형모델 추천)




[ RF ]  :  복수의 DT 를 묶어 예측에 대한 투표를 하는 방식
 과적합 최적화
    - 트리의 깊이를 제한하여 복잡한 의사결정 함수 사용 X
    - 적합 도중 데이터 포이트와 특징을 보여주지 않는 것 (과적합을 위한 충분한 데이터 제공 X)

 배깅을 사용하여 내장된 검증 기능
      랜덤 샘플 추출 : bag
      나머지		: OOB (out of bag)
      
replacement : 겹치는 데이터가 각 백에 허용되는것을 의미  (bootstrapping)
     -> 인공적으로 백에 더 많은 변종을 더하는 것
     
  ```   
from  sklearn.ensemble import RandomForestClassifier    (보통 DecisionTreeClassifier(splitter='best')로 고정)
clf = RandomClassifier(n_estimators = ,
					   max_depth= ,
                       n_jobs = ,         # 코어 수 지정 ( 개수에 비례하여 속도 빨라짐 ) -1 : 모든 코어 사용
					   criterion = ' ',   # 기준  'gini' (def) : gini imputer, 'entropy' : gain
					   max_features=' ',  # 추출할 샘플 개수? 'auto' (def) == 'sqrt' ,'log2'
					   oob_score= )   # OOB 점수 계산
```

- - -

Gradient boosting regression tree

 : 이전 트리의 오차를 보완해나가는 방식으로 순차적 트리를 만듬.

	무작위성이 없으며, 강력한 pre-pruning 사용
	깊지 않은트리를 많이 만들어 연결함..
    이때, 각 트리는 데이터의 일부에 대해서만 예측을 잘 수행하기때문에 트기 많이 추가될수록 성능이 좋아진다.


![](https://github.com/VFV-main/ML/blob/main/download.png?raw=true)

 - 랜덤 포레스트와 비슷한 특성을 강조하지만 일부 특성을 완전히 무시함


	안정적인 랜덤포레스트를 먼저 작동하는것을 추천하며 , 예측 시간이 중요하거나 성능을 극한으로 높이고 싶다면 이 부스팅을 사용하면 도움이 된다.
    대규모의 머신러닝 문제에 부스팅을 적용하려면 xgboost 를 사용해 빠르게 처리할 수 있다. (LightGBM , CatBoost...)
    
* 중요한 매개변수
  learning rate : ( 이전 트리의 오차를 얼마나 강하게 보정할 것인지)
  n_estimators  : 랜덤 포레스트와 달리 생성 트리가 많으면 모델이 복잡해지며 과적합 경향
  
보통은 시간과 메모리를 고려해 n_estimators 를 맞춘 후 적절한 learning rate 를 찾음
  
```
from sklearn.ensemble import GradientBoostingClassfier
gb = GradientBoostingClassifier(max_depth=,
							 	learning_rate = 
                                n_iter_no_change= 	# 조기종료를 위한 반복횟수 지정 (반복횟수동안 검증점수 향상이 없다면 종료)
                                validation_fraction = ) # 훈련데이터에서 검증데이터로 사용할 데이터의 비율 지정
```


장점

 - 특성의 스케일 조정을 할 필요가 없음
 - 이진 특성이나 연속적인 특성에서도 잘 작동함
 
단점

 - 매개변수의 중요도가 높으며, 훈련시간이 김 . 
 - 고차원의 희소한 데이터에는 잘 작동하지 않음
 
 
_ _ _


Bagging (Bootstrap aggregating)

: 중복을 허용한 랜덤 샘플링으로 만든 훈련 세트를 사용하여 분류기를 각각 다르게 학습
   (단순히 랜덤포레스트에서 특성 재구성을 제외한 것)

predict_proba() 메서드를 지원하는 경우 활률값을 평균내어 예측 수행
그렇지 않다면  가장 빈도가 높은 클래스 레이블로 예측

```
from sklearn.ensemble import BaggingClassifier
bag = BaggingClassifier(LogisticRegressioin(), # 분류기 지정
						n_estimators = ,	   
                        max_samples = ,			# 부트스트랩 샘플 크기 지정
                        oob_score = ,      # OOB (out of bag  : 오차) 를 사용하여 bootstraping 에 포함되지 않은 샘플을 기반으로 훈련된 모델을 평가 (Random Forest도 지원
                        n_jobs= )
)
```
_ _ _

Extra tree
: 랜덤포레스트와 유사하지만  DecisionTreeClassifier(splitter='random') 분류기를 사용하고 부트스트랩 샘플링을 적용하지 않는다.

무작위성을 증가시키면 일반적으로 모델의 편향은 늘어나지만 분산이 감소하여 과소적합이 생길 수 있다.


![](https://github.com/VFV-main/ML/blob/main/extra%20tree.png?raw=true)

랜덤 포레스트와 성능은 비슷하다.
하지만 무작위 분할의 이유로 일반화 성능을 높이기 위해서는 더 많은 트리를 만들어야 하기때문에 일반적으로 랜덤 포르스트를 선호한다.
