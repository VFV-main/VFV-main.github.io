---
layout: post
title: 'Supervised Learning'
categories: [ML]
tags: [ML]
---

머신러닝은 보통 지도학습과 비지도학습 구분짓고 있다.
단지 입력데이터와 출력데이터가 보장되느냐 그렇지 않느냐의 차이이다.

그중 지도학습은  크게 분류, 회귀로 재차 나눌 수 있다.

분류에서는  
- 예/아니오 [이진 분류]
 - 양성 클래스 (Positive)
 - 음성 클래스 (Negative)

두 가지로 나눌 수 있다 , 이 기준은 주관적이며 문제에 따라 다르게 정의 될 수 있다.
- 상/중/하   [다중 분류]

iris 데이터에서의 꽃 종류들로 분류하는것을 예로 들 수 있다.


회귀는 연속적인 숫자, 실수들을 예측하는 것으로,

- 나이
- 가격
- 상품의 양

보통 어떤 양이나 일정 범위안의 어떠한 숫자,수치가 될 수 있다.


**출력 값에 연속성이 있는지 생각해보면 회귀와 분류는 쉽게 구분할 수 있게 된다.**


 *예측성*
- ** 일반화  과대적합 과소적합**

**일반화** : 모델이 입력하는 데이터에 대하여 정확하게 예측을 할 수 있는것

**과대적합** : 모델이 예측을 할 때 훈련된 데이터에 대해서 과도하게 적합이 된것  (Overfitting)
          - 변수들을 불필요하게 많이 또는 모두 활용하여 모델이 복잡해지게 됨.

**과소적합** : 예측을 할 때 모델이 단순화 되어 예측에 필요한 중요한 변수를 놓치게 되며 예측을 잘 하지 못하는것 (Underfitting)

즉 , 모델은 복잡할수록 (훈련데이터를 많이 활용할수록) 더 정확히 예측할 수 있지만 
  훈련데이터에 민감해져 새로운 데이터에 대해 일반화를 잘 하지 못하게 된다.


그렇다면 일반화의 성능이 최대로 만드는 방법은 무엇일까?

데이터셋에 다양한 ++**데이터가 많을수록**++ 과대적합 없이 더 복잡한 모델을 만들 수 있다.
( 중복된 데이터나 유사한 데이터들은 도움이 되지 않음 )

